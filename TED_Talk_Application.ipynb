{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ~TED TALK SHARES PREDICTION~\n",
    "\n",
    "TED \n",
    " 1. Exploraty analysis  \n",
    "         kdjflkdjlf \n",
    " 2. Linear regression \n",
    "     lkjdf \n",
    " 3. Neurual \n",
    "     lkdkjfldjf\n",
    "."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from scipy import stats\n",
    "import matplotlib.pyplot as plt\n",
    "import json\n",
    "from pandas.io.json import json_normalize\n",
    "import textblob\n",
    "from textblob import TextBlob\n",
    "from collections import Counter\n",
    "import datetime\n",
    "import re\n",
    "import nltk\n",
    "import operator\n",
    "from sklearn import linear_model\n",
    "from sklearn.metrics import mean_squared_error, r2_score\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn import metrics\n",
    "from sklearn.model_selection import train_test_split\n",
    "import time\n",
    "import h5py\n",
    "import scipy\n",
    "from PIL import Image\n",
    "from scipy import ndimage\n",
    "\n",
    "df = pd.read_csv('./ted_main.csv')\n",
    "df3 = pd.read_csv(\"./transcripts.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Feature Extraction\n",
    "\n",
    "## Date Convertion\n",
    "\n",
    "<img src=\"date.png\" title=\"Title text\" />"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df['film_date'] = df['film_date'].apply(lambda x: datetime.datetime.fromtimestamp( int(x)).strftime('%d-%m-%Y'))\n",
    "df['published_date'] = df['published_date'].apply(lambda x: datetime.datetime.fromtimestamp( int(x)).strftime('%d-%m-%Y'))\n",
    "\n",
    "df['published_date'] = pd.to_datetime(df['published_date'])\n",
    "df['film_date'] = pd.to_datetime(df['film_date'])\n",
    "\n",
    "temp = datetime.date(2018,1,1)\n",
    "temp = pd.to_datetime(temp)\n",
    "df['published_date'] = temp - df['published_date']\n",
    "df['film_date'] = temp - df['film_date']\n",
    "\n",
    "df['published_date'] = df['published_date'].dt.days\n",
    "df['film_date'] = df['film_date'].dt.days"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Top 35 Tags extraction\n",
    "\n",
    "<img src=\"tags.png\" title=\"Title text\" />"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2550, 52)\n"
     ]
    }
   ],
   "source": [
    "df2 = df['tags']\n",
    "temp = {}\n",
    "for each in df2.values:\n",
    "    list = each.split()\n",
    "    for every in list:\n",
    "        test = re.sub('[^A-Za-z0-9]+', ' ', every)\n",
    "        test = test.lower()\n",
    "        if test in temp.keys():\n",
    "            temp[test] +=  1\n",
    "        else:\n",
    "            temp[test]= 1\n",
    "            \n",
    "new = pd.DataFrame.from_dict(temp, orient=\"index\")\n",
    "#print(new.sort_values(by = 0, ascending=False).head(15))\n",
    "topTags = new.sort_values(by = 0, ascending=False).head(35).index\n",
    "newtopTags = []\n",
    "for i in topTags:\n",
    "    newtopTags.append(i.strip())\n",
    "#print(newtopTags)\n",
    "xx = pd.DataFrame(0, index=np.arange(len(df)), columns=newtopTags)\n",
    "#print(xx.shape)\n",
    "for i in range(len(df)):\n",
    "    for j in topTags:\n",
    "        j = str(j).strip()\n",
    "        if str(j) in str(df['tags'][i]).lower():\n",
    "            xx[str(j)][i] = 1\n",
    "frames = [df, xx]\n",
    "result = pd.concat(frames, axis=1)\n",
    "print(result.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Sentiment Polarity Extraction - NLP\n",
    "\n",
    "<img src=\"transcript.png\"  title=\"Title text\" />"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2467, 55)\n"
     ]
    }
   ],
   "source": [
    "polarity = []\n",
    "subj = []\n",
    "for t in df3['transcript']:\n",
    "    tx = TextBlob(t)\n",
    "    polarity.append(tx.sentiment.polarity)\n",
    "    subj.append(tx.sentiment.subjectivity)\n",
    "df3['polarity'] = polarity\n",
    "df3['subjectivity'] = subj\n",
    "result = result.merge(df3,on = 'url', how='inner')\n",
    "print(result.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Ratings Feature Extraction\n",
    "\n",
    "<img src=\"rating.png\" title=\"Title text\" />"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2467, 69)\n"
     ]
    }
   ],
   "source": [
    "result['ratings'] = result['ratings'].apply(lambda x: eval(str(x)))\n",
    "json_data = result['ratings'] # your list with json objects (dicts)\n",
    "newRatings = ['Funny','Beautiful','Ingenious','Courageous','Longwinded','Confusing','Informative','Fascinating','Unconvincing','Persuasive','Jaw-dropping','OK','Obnoxious','Inspiring']\n",
    "yy = pd.DataFrame(0, index=np.arange(len(result)), columns=newRatings)\n",
    "ind = 0\n",
    "for i in json_data:\n",
    "    for j in i:\n",
    "        temp = j['name']\n",
    "        yy[temp][ind] = j['count']\n",
    "    ind +=1\n",
    "\n",
    "#print(result.shape)\n",
    "#print(yy.shape)\n",
    "frame1 = [result, yy]\n",
    "result = pd.concat(frame1, axis=1)\n",
    "print(result.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Description & Title Sujectivity Feature Extraction\n",
    "\n",
    "<img src=\"title.png\" title=\"Title text\" />"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2467, 71)\n",
      "(2467, 73)\n"
     ]
    }
   ],
   "source": [
    "tem1 = []\n",
    "tem2 = []\n",
    "tem3 = result['description']\n",
    "#print(type(tem3))\n",
    "for i in tem3:\n",
    "    tem = TextBlob(i)\n",
    "    tem1.append(tem.sentiment.subjectivity) \n",
    "    tem2.append(tem.sentiment.polarity)\n",
    "    \n",
    "result['des_subj'] = tem1\n",
    "result['des_sent'] = tem2\n",
    "result.columns\n",
    "print(result.shape)\n",
    "\n",
    "tem1 = []\n",
    "tem2 = []\n",
    "tem3 = result['title']\n",
    "#print(type(tem3))\n",
    "for i in tem3:\n",
    "    tem = TextBlob(i)\n",
    "    tem1.append(tem.sentiment.subjectivity) \n",
    "    tem2.append(tem.sentiment.polarity)\n",
    "    \n",
    "result['tit_subj'] = tem1\n",
    "result['tit_sent'] = tem2\n",
    "result.columns\n",
    "print(result.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Speaker Occupcation Feature Extraction\n",
    "\n",
    "<img src=\"speak.png\" title=\"Title text\" />"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2467, 83)\n"
     ]
    }
   ],
   "source": [
    "li = result['speaker_occupation']\n",
    "lli=[]\n",
    "lis = []\n",
    "for i in li:\n",
    "    if type(i) == str:\n",
    "        k = i.lower().replace('/',',').replace(';',',').split(',')\n",
    "        lis.append(k)\n",
    "        for j in k:\n",
    "            lli.append(j.strip().lower())\n",
    "    else:\n",
    "        lis.append([])\n",
    "        pass\n",
    "lid = Counter(lli)\n",
    "\n",
    "authdf = pd.DataFrame.from_dict(lid, orient=\"index\").sort_values(by=0, ascending=False).head(10).index\n",
    "newauth = pd.DataFrame(0, index=np.arange(len(result)), columns=authdf)\n",
    "for i in range(len(result)):\n",
    "    for j in authdf:\n",
    "        if str(j) in lis[i]:\n",
    "            newauth[str(j)][i] = 1\n",
    "        \n",
    "frames3 = [result, newauth]\n",
    "result = pd.concat(frames3, axis=1)\n",
    "print(result.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['index', 'comments', 'duration', 'film_date', 'languages',\n",
      "       'num_speaker', 'published_date', 'views', 'technology', 'science',\n",
      "       'global', 'issues', 'culture', 'tedx', 'design', 'business', 'change',\n",
      "       'entertainment', 'social', 'ted', 'health', 'innovation', 'society',\n",
      "       'art', 'future', 'communication', 'biology', 'creativity', 'humanity',\n",
      "       'collaboration', 'environment', 'economics', 'medicine', 'brain',\n",
      "       'activism', 'education', 'community', 'history', 'fellows', 'children',\n",
      "       'music', 'invention', 'care', 'polarity', 'subjectivity', 'Funny',\n",
      "       'Beautiful', 'Ingenious', 'Courageous', 'Longwinded', 'Confusing',\n",
      "       'Informative', 'Fascinating', 'Unconvincing', 'Persuasive',\n",
      "       'Jaw-dropping', 'OK', 'Obnoxious', 'Inspiring', 'des_subj', 'des_sent',\n",
      "       'tit_subj', 'tit_sent', 'writer', 'author', 'designer', 'artist',\n",
      "       'entrepreneur', 'inventor', 'activist', 'journalist', 'educator',\n",
      "       'psychologist'],\n",
      "      dtype='object')\n"
     ]
    }
   ],
   "source": [
    "xyz = result.describe().reset_index()\n",
    "print(xyz.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([  2.35900000e+03,   7.30000000e+01,   1.40000000e+01,\n",
       "          1.10000000e+01,   6.00000000e+00,   0.00000000e+00,\n",
       "          1.00000000e+00,   1.00000000e+00,   0.00000000e+00,\n",
       "          2.00000000e+00]),\n",
       " array([   155895. ,   4863016.5,   9570138. ,  14277259.5,  18984381. ,\n",
       "         23691502.5,  28398624. ,  33105745.5,  37812867. ,  42519988.5,\n",
       "         47227110. ]),\n",
       " <a list of 10 Patch objects>)"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYAAAAEJCAYAAACdePCvAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nqXU7G7dyVL0AAAAASUVORK5CYII=\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x26b190a6080>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.hist((result['views']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([  26.,  180.,  532.,  959.,  475.,  185.,   64.,   28.,   14.,    4.]),\n",
       " array([ 5.19283219,  5.4409681 ,  5.68910402,  5.93723994,  6.18537586,\n",
       "         6.43351178,  6.6816477 ,  6.92978362,  7.17791953,  7.42605545,\n",
       "         7.67419137]),\n",
       " <a list of 10 Patch objects>)"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYAAAAD8CAYAAAB+UHOxAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x26b18ec2438>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.hist(np.log10(result['views']))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Regression Model Implementation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X_temp = result[[ 'comments', 'duration', 'film_date', 'languages',\n",
    "       'num_speaker', 'published_date', 'views', 'technology', 'science',\n",
    "       'global', 'issues', 'culture', 'tedx', 'design', 'business', 'change',\n",
    "       'entertainment', 'social', 'ted', 'health', 'innovation', 'society',\n",
    "       'art', 'future', 'communication', 'biology', 'creativity', 'humanity',\n",
    "       'collaboration', 'environment', 'economics', 'medicine', 'brain',\n",
    "       'activism', 'education', 'community', 'history', 'fellows', 'children',\n",
    "       'music', 'invention', 'care', 'polarity', 'subjectivity', 'des_subj', 'des_sent',\n",
    "       'tit_subj', 'tit_sent', 'writer', 'author', 'designer', 'artist',\n",
    "       'entrepreneur', 'inventor', 'activist', 'journalist', 'educator',\n",
    "       'psychologist']]\n",
    "y = np.log10(result['views'])\n",
    "\n",
    "mu = X_temp.mean(axis=0)\n",
    "stdv = X_temp.std(axis = 0)\n",
    "X = (X_temp - mu)/stdv\n",
    "#X['views'] = y"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Regression Result on Training Set:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Data Summary\n",
      "=======================\n",
      "Linear Regression Score on Training Data: 71.73723908183266% \n",
      "\n",
      "Ridge Regression Scores on Training:\n",
      "====================================\n",
      "Score with Alpha 0 is 71.73723908183266%\n",
      "Score with Alpha 0.1 is 71.17890503354356%\n",
      "Score with Alpha 0.5 is 66.16914668395114%\n",
      "Score with Alpha 5 is 31.432496013009036%\n"
     ]
    }
   ],
   "source": [
    "print(\"Training Data Summary\")\n",
    "print(\"=======================\")\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.10, random_state=324)\n",
    "Lreg = linear_model.LinearRegression(normalize=True)\n",
    "Lreg.fit(X_train, y_train)\n",
    "predicted = Lreg.predict(X_train)\n",
    "temp1 = Lreg.score(X_train,y_train)\n",
    "print(\"Linear Regression Score on Training Data: {}% \\n\".format(temp1*100))\n",
    "\n",
    "print(\"Ridge Regression Scores on Training:\")\n",
    "print(\"====================================\")\n",
    "li = [0,0.1,0.5,5]\n",
    "regli = []\n",
    "for i in li:\n",
    "    Rreg = linear_model.Ridge(normalize = True, alpha = i)\n",
    "    Rreg.fit(X_train, y_train)\n",
    "    regli.append(Rreg)\n",
    "    predicted1 = Lreg.predict(X_train)\n",
    "    temp2 = Rreg.score(X_train,y_train)\n",
    "    print(\"Score with Alpha {} is {}%\".format(i,temp2*100))\n",
    "    #print(temp2*100)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Regression Result on Testing Set:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Testing Data Summary\n",
      "====================\n",
      "Linear Regression Score on testing Data is 69.27500503091655% \n",
      "\n",
      "Ridge Regression Scores on Testing:\n",
      "===================================\n",
      "Score with Alpha 0 is 69.27500503091655%\n",
      "Score with Alpha 0.1 is 68.96255931822965%\n",
      "Score with Alpha 0.5 is 64.94461970294189%\n",
      "Score with Alpha 5 is 30.84202870867153%\n"
     ]
    }
   ],
   "source": [
    "print(\"Testing Data Summary\")\n",
    "print(\"====================\")\n",
    "predicted2 = Lreg.predict(X_test)\n",
    "temp4 = Lreg.score(X_test,y_test)\n",
    "print(\"Linear Regression Score on testing Data is {}% \\n\".format(temp4*100))\n",
    "#print(metrics.r2_score(predicted1, y_test)*100)\n",
    "\n",
    "print(\"Ridge Regression Scores on Testing:\")\n",
    "print(\"===================================\")\n",
    "for j in range(4):\n",
    "    predicted2 = regli[j].predict(X_test)\n",
    "    temp3 = regli[j].score(X_test,y_test)\n",
    "    print(\"Score with Alpha {} is {}%\".format(li[j],temp3*100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "### Writing to csv file for Neural Network\n",
    "\n",
    "X.to_csv(\"./new1.csv\")\n",
    "y.to_csv(\"./new2.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Deep Neural Network for Regression\n",
    "\n",
    "## 3 layers with (100,50,1) hidden units are designed with following options\n",
    "\n",
    "  **1 ** ) **Hyper Paremters Initialization**\n",
    "                 - HE Initialization\n",
    "  **2 ** ) **Forward Propogation**\n",
    "                 - L layers use Relu activation function\n",
    "  **3 ** ) **Regulariztion**\n",
    "                 - lambda with L2 regularization\n",
    "  **4 ** )  **Cost**\n",
    "                 - MSE\n",
    "  **5 ** ) **Optimization**\n",
    "                 - Gradient Descent Algorithm\n",
    "                 \n",
    "### Algorithm Steps:\n",
    "                 \n",
    "##### Forward propogration ---> calculate cost ---> Backward Propogation ---> Gradient Derivative --> Update Prameter for n iterations\n",
    "."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2220, 1)\n",
      "(58, 2220)\n"
     ]
    }
   ],
   "source": [
    "Xpd = pd.read_table(\"./new1.csv\", index_col=0, sep=',')\n",
    "ypd = pd.read_table(\"./new2.csv\", index_col=0, sep=',', header=None)\n",
    "X_el = np.matrix(Xpd)\n",
    "Y_el = np.matrix(ypd)\n",
    "X, X_test, Y, y_test = train_test_split(X_el, Y_el, test_size=0.10, random_state=324)\n",
    "X = X.T\n",
    "print(Y.shape) #(m,1)\n",
    "print(X.shape) #(n,m)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Hyper Parameter (W, b) Initialization\n",
    "\n",
    "**HE Initiallization ** : This function is similar to the previous `initialize_parameters_random(...)`. The only difference is that instead of multiplying `np.random.randn(..,..)` by 10, you will multiply it by $\\sqrt{\\frac{2}{\\text{dimension of the previous layer}}}$, which is what He initialization recommends for layers with a ReLU activation. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def initialize_parameters_deep(layers_dims,initialization=\"he\"):\n",
    "\n",
    "    np.random.seed(3)\n",
    "    parameters = {}\n",
    "    L = len(layers_dims)            # number of layers in the network\n",
    "    \n",
    "\n",
    "    for l in range(1, L):\n",
    "        \n",
    "        if initialization == \"zeros\":\n",
    "            parameters['W' + str(l)] = np.zeros((layers_dims[l], layers_dims[l-1]))\n",
    "            parameters['b' + str(l)] = np.zeros((layers_dims[l],1))\n",
    "        elif initialization == \"random\":\n",
    "            parameters['W' + str(l)] = np.random.randn(layers_dims[l],layers_dims[l-1]) * 0.01\n",
    "            parameters['b' + str(l)] = np.zeros((layers_dims[l],1))\n",
    "        elif initialization == \"he\":\n",
    "            parameters['W' + str(l)] = np.random.randn(layers_dims[l],layers_dims[l-1]) * np.sqrt(2/layers_dims[l-1])\n",
    "            parameters['b' + str(l)] = np.zeros((layers_dims[l],1))\n",
    "        \n",
    "        assert(parameters['W' + str(l)].shape == (layers_dims[l], layers_dims[l-1]))\n",
    "        assert(parameters['b' + str(l)].shape == (layers_dims[l], 1))\n",
    "\n",
    "        \n",
    "    return parameters"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "# Foward Propogation\n",
    "\n",
    "."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def sigmoid(z):\n",
    "\n",
    "    s = 1/(1+np.exp(-z))\n",
    "    return s,z\n",
    "\n",
    "def relu(z):\n",
    "    s = (abs(z) + z) / 2\n",
    "    return s,z"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def linear_forward(A, W, b):\n",
    "\n",
    "    Z = np.dot(W,A) + b\n",
    "    assert(Z.shape == (W.shape[0], A.shape[1]))\n",
    "    cache = (A, W, b)\n",
    "    \n",
    "    return Z, cache"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def linear_activation_forward(A_prev, W, b, activation):\n",
    "\n",
    "    if activation == \"sigmoid\":\n",
    "        # Inputs: \"A_prev, W, b\". Outputs: \"A, activation_cache\".\n",
    "        Z, linear_cache = linear_forward(A_prev,W,b)\n",
    "        #Z = np.dot(W,A_prev) + b\n",
    "        A, activation_cache = sigmoid(Z)\n",
    "        #print(\"sigmoid\")\n",
    "    \n",
    "    elif activation == \"relu\":\n",
    "        # Inputs: \"A_prev, W, b\". Outputs: \"A, activation_cache\".\n",
    "        Z, linear_cache = linear_forward(A_prev,W,b)\n",
    "        #Z = np.dot(W,A_prev) + b\n",
    "        A, activation_cache = relu(Z)\n",
    "        #print(\"relu\")\n",
    "    \n",
    "    assert (A.shape == (W.shape[0], A_prev.shape[1]))\n",
    "    cache = (linear_cache, activation_cache)\n",
    "\n",
    "    return A, cache"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def L_model_forward(X, parameters,keep_prob=1):\n",
    "\n",
    "\n",
    "    caches = []\n",
    "    A = X\n",
    "    L = len(parameters) // 2                  # number of layers in the neural network\n",
    "    # Implement [LINEAR -> RELU]*(L-1). Add \"cache\" to the \"caches\" list.\n",
    "    for l in range(1, L):\n",
    "        A_prev = A \n",
    "        #print(A_prev.shape)\n",
    "        A, cache = linear_activation_forward(A_prev, parameters['W' + str(l)] ,parameters['b' + str(l)], \"relu\")\n",
    "        D = np.random.rand(A.shape[0],A.shape[1])\n",
    "        D = D < keep_prob\n",
    "        A = np.multiply(A,D )\n",
    "        A = A/keep_prob\n",
    "        cache = cache + (D,)\n",
    "        caches.append(cache)\n",
    "    \n",
    "    # Implement LINEAR -> SIGMOID. Add \"cache\" to the \"caches\" list.\n",
    "    AL, cache = linear_activation_forward(A,parameters['W' + str(L)] ,parameters['b' + str(L)],\"relu\" )\n",
    "    caches.append(cache)\n",
    "    assert(AL.shape == (1,X.shape[1]))\n",
    "            \n",
    "    return AL, caches"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Cost Computation \n",
    "## L2 Regularization\n",
    "\n",
    "The standard way to avoid overfitting is called **L2 regularization**. It consists of appropriately modifying your cost function, from:\n",
    "$$J = \\frac{1}{2m} \\sum\\limits_{i = 1}^{m} \\left(y^{(i)}- a^{[L](i)}\\right)^{2} \\tag{1}$$\n",
    "To:\n",
    "$$J_{regularized} = \\small \\underbrace{\\frac{1}{2m} \\sum\\limits_{i = 1}^{m} \\left(y^{(i)}- a^{[L](i)}\\right)^{2} }_\\text{cross-entropy cost} + \\underbrace{\\frac{1}{m} \\frac{\\lambda}{2} \\sum\\limits_l\\sum\\limits_k\\sum\\limits_j W_{k,j}^{[l]2} }_\\text{L2 regularization cost} \\tag{2}$$\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def compute_cost(AL, Y,parameters,lambd,regularized=False):\n",
    "\n",
    "    m = Y.shape[1]\n",
    "    cross_entropy_cost = (1/(2*m))* np.sum(np.square(AL - Y))\n",
    "    loop_len = len(parameters)//2\n",
    "    \n",
    "    if regularized == True:\n",
    "        temp = 0\n",
    "        for i in range(1,loop_len+1):\n",
    "            temp += np.sum(np.square(parameters['W' + str(i)]))\n",
    "        L2_regularization_cost = (1/m) * (lambd/2) * temp\n",
    "        cost = cross_entropy_cost + L2_regularization_cost\n",
    "    else:\n",
    "        cost = cross_entropy_cost\n",
    "\n",
    "    cost = np.squeeze(cost)\n",
    "    assert(cost.shape == ())\n",
    "    \n",
    "    return cost"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Back Propogation\n",
    "\n",
    "."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def linear_backward(dZ, cache,D,lambd,keep_prob,val):\n",
    "\n",
    "    #linear_cache, activation_cache,D = cache\n",
    "\n",
    "    linear_cache, activation_cache, dummy= cache\n",
    "    A_prev, W, b = linear_cache\n",
    "    m = A_prev.shape[1]\n",
    "    dA_prev = np.dot(W.T, dZ)\n",
    "    if val ==0:\n",
    "        dZ_prev = None\n",
    "    else:\n",
    "        dA_prev = np.multiply(dA_prev,D )\n",
    "        dA_prev = dA_prev/keep_prob\n",
    "        dZ_prev = np.multiply(dA_prev, np.int64(A_prev > 0))\n",
    "    \n",
    "    dW = (1./m) * np.dot(dZ,A_prev.T) + ((lambd/m) * W)\n",
    "    db = (1./m) * np.sum(dZ,axis=1)\n",
    "    assert (dA_prev.shape == A_prev.shape)\n",
    "    assert (dW.shape == W.shape)\n",
    "    assert (db.shape == b.shape)\n",
    "    return dZ_prev, dA_prev, dW, db"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def L_model_backward(AL, Y, caches, lambd,keep_prob):\n",
    "\n",
    "    grads = {}\n",
    "    L = len(caches) # the number of layers\n",
    "    #print(L)\n",
    "    m = AL.shape[1]\n",
    "    Y = Y.reshape(AL.shape) # after this line, Y is the same shape as AL\n",
    "    \n",
    "    # Initializing the backpropagation and dZL for last layer \n",
    "    dAL = - (np.divide(Y, AL) - np.divide(1 - Y, 1 - AL))\n",
    "    linear_cache, activation_cache = caches[L-1]\n",
    "    A_prev2, W3, b3 = linear_cache\n",
    "    \n",
    "    dZ_prev3 = AL - Y\n",
    "    grads[\"dW\" + str(L)] = 1./m * np.dot(dZ_prev3, A_prev2.T)+((lambd/m) * W3)\n",
    "    grads[\"db\" + str(L)] = 1./m * np.sum(dZ_prev3, axis=1)\n",
    "    \n",
    "    dA_prev2 = np.dot(W3.T, dZ_prev3)\n",
    "    linear_cache, activation_cache,D = caches[L-2]\n",
    "    dA_prev2 = np.multiply(D,dA_prev2)\n",
    "    dA_prev2 = dA_prev2/keep_prob\n",
    "    dZ = np.multiply(dA_prev2, np.int64(A_prev2 > 0))\n",
    "    x, y,D_prev = caches[L-3]\n",
    "    \n",
    "    # Loop from l=L-2 to l=0\n",
    "    for l in reversed(range(L)):\n",
    "        # lth layer: (RELU -> LINEAR) gradients.\n",
    "        # Inputs: \"grads[\"dA\" + str(l + 1)], current_cache\". Outputs: \"grads[\"dA\" + str(l)] , grads[\"dW\" + str(l + 1)] , grads[\"db\" + str(l + 1)] \n",
    "        current_cache = caches[l-1]\n",
    "        D = D_prev\n",
    "        val = l - 1\n",
    "        dZ_prev, dA_prev_temp, dW_temp, db_temp = linear_backward(dZ, current_cache, D,lambd,keep_prob, val)\n",
    "        if val ==0:\n",
    "            pass\n",
    "        else:\n",
    "            x, y, D_prev = caches[l-2]\n",
    "        dZ = dZ_prev\n",
    "        #grads[\"dA\" + str(l)] = dA_prev_temp\n",
    "        grads[\"dW\" + str(l)] = dW_temp\n",
    "        grads[\"db\" + str(l)] = db_temp\n",
    "        if val ==0:\n",
    "            break\n",
    "    \n",
    "    return grads"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Updating Hyper Parameters Based on Gradient Descent Derivative\n",
    "\n",
    "."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def update_parameters(parameters, grads, learning_rate):\n",
    "\n",
    "    L = len(parameters) // 2 # number of layers in the neural network\n",
    "\n",
    "    # Update rule for each parameter. Use a for loop.\n",
    "    for l in range(L):\n",
    "        parameters[\"W\" + str(l+1)] = parameters[\"W\" + str(l+1)] - learning_rate * grads[\"dW\" + str(l + 1)]\n",
    "        parameters[\"b\" + str(l+1)] = parameters[\"b\" + str(l+1)] - learning_rate * grads[\"db\" + str(l + 1)]\n",
    "    return parameters\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Deep Learning Model\n",
    "\n",
    "."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def model(X, Y, learning_rate = 0.3, num_iterations = 10000, print_cost = True, lambd = 0.01, keep_prob = 1):\n",
    "        \n",
    "    grads = {}\n",
    "    costs = []                            # to keep track of the cost\n",
    "    m = X.shape[1]                        # number of examples\n",
    "    layers_dims = [X.shape[0],100,50, 1]\n",
    "    parameters = initialize_parameters_deep(layers_dims,\"random\")\n",
    "\n",
    "    # Loop (gradient descent)\n",
    "    for i in range(0, num_iterations):\n",
    "        AL, cache = L_model_forward(X, parameters,keep_prob)\n",
    "        cost = compute_cost(AL, Y.T,parameters,lambd,True)\n",
    "        grads = L_model_backward(AL, Y, cache, lambd,keep_prob)\n",
    "\n",
    "        parameters = update_parameters(parameters, grads, learning_rate)\n",
    "        \n",
    "        if print_cost and i % 1000 == 0:\n",
    "            print(\"Cost after iteration {}: {}\".format(i, cost))\n",
    "            if (i>= 3000):\n",
    "                x = str(input(\"Wanna continue?\"))\n",
    "                if x == str(\"No\"):\n",
    "                    break\n",
    "        if print_cost and i % 1000 == 0:\n",
    "            costs.append(cost)\n",
    "    \n",
    "    # plot the cost\n",
    "    plt.plot(costs)\n",
    "    plt.ylabel('cost')\n",
    "    plt.xlabel('iterations (x1,000)')\n",
    "    plt.title(\"Learning rate =\" + str(learning_rate))\n",
    "    plt.show()\n",
    "    \n",
    "    return parameters,grads"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\gokul\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:10: RuntimeWarning: divide by zero encountered in true_divide\n",
      "  # Remove the CWD from sys.path while we load stuff.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cost after iteration 0: 18.61153052625323\n",
      "Cost after iteration 1000: 0.00471955334046848\n",
      "Cost after iteration 2000: 0.004225699628308712\n",
      "Cost after iteration 3000: 0.004041585928844044\n",
      "Wanna continue?n\n",
      "Cost after iteration 4000: 0.003951495801268497\n",
      "Wanna continue?n\n",
      "Cost after iteration 5000: 0.00389731839165323\n",
      "Wanna continue?n\n",
      "Cost after iteration 6000: 0.0038608467054401796\n",
      "Wanna continue?n\n",
      "Cost after iteration 7000: 0.0038390689707865798\n",
      "Wanna continue?n\n",
      "Cost after iteration 8000: 0.003822530323513884\n",
      "Wanna continue?a\n",
      "Cost after iteration 9000: 0.0038087875762504945\n",
      "Wanna continue?df\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYwAAAEWCAYAAAB1xKBvAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\ngAhhM54AAAAASUVORK5CYII=\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x1c1df9c28d0>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "parameters,grads = model(X, Y, lambd=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "On the train set:\n",
      "=================\n",
      "Score: 98.59803918720111%\n",
      "On the Testing set:\n",
      "===================\n",
      "Score: 97.645169072843%\n"
     ]
    }
   ],
   "source": [
    "print(\"On the train set:\")\n",
    "print(\"=================\")\n",
    "AL, xx = L_model_forward(X, parameters)\n",
    "te = metrics.r2_score(AL.T, Y)\n",
    "print(\"Score: {}%\".format(te*100))\n",
    "print(\"On the Testing set:\")\n",
    "print(\"===================\")\n",
    "Y_predicted, xx = L_model_forward(X_test.T, parameters)\n",
    "tem = metrics.r2_score(Y_predicted.T, y_test)\n",
    "print(\"Score: {}%\".format(tem*100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 6.30752898  5.84710542  6.0216837   5.71843276  5.88094215]]\n",
      "[[ 6.28969568  5.77760666  6.01232121  5.76266762  5.91016458]]\n"
     ]
    }
   ],
   "source": [
    "print(y_test[:5].T)\n",
    "print(Y_predicted[0,:5])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Conclusion:\n",
    "\n",
    "##### This system can be effectively used by TED organization to predict the reach of a new video. For example, if a new video is recorded with features like Technology genere, certain duration, particular speaker, particular tags and with particular sentiment and polarity content we can say it will reach certain views after these many days with 97% confidence"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
